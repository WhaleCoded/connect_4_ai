{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "BOARD_WIDTH = 7\n",
    "BOARD_HEIGHT = 6\n",
    "MAX_BOARDS = 100_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_moves_to_game_board(moves):\n",
    "    moves_by_column = {}\n",
    "\n",
    "    curr_player = 1\n",
    "    for move in moves:\n",
    "        col_index = int(move) - 1\n",
    "\n",
    "        if col_index not in moves_by_column:\n",
    "            moves_by_column[col_index] = []\n",
    "\n",
    "        moves_by_column[col_index].append(curr_player)\n",
    "\n",
    "        if curr_player == 1:\n",
    "            curr_player = -1\n",
    "        else:\n",
    "            curr_player = 1\n",
    "\n",
    "    game_board = np.zeros((BOARD_WIDTH, BOARD_HEIGHT), dtype=np.int8)\n",
    "    for col_index, moves in moves_by_column.items():\n",
    "        for row_index, move in enumerate(moves):\n",
    "            game_board[col_index][row_index] = move\n",
    "\n",
    "    return game_board\n",
    "\n",
    "def get_col_scores(entries):\n",
    "    col_scores = np.zeros(BOARD_WIDTH)\n",
    "\n",
    "    for col_index, col_score in enumerate(entries):\n",
    "        col_scores[col_index] = int(col_score)\n",
    "\n",
    "    return col_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import convolve2d\n",
    "\n",
    "horizontal_kernel = np.array([[ 1, 1, 1, 1]])\n",
    "vertical_kernel = np.transpose(horizontal_kernel)\n",
    "diag1_kernel = np.eye(4, dtype=np.uint8)\n",
    "diag2_kernel = np.fliplr(diag1_kernel)\n",
    "detection_kernels = [horizontal_kernel, vertical_kernel, diag1_kernel, diag2_kernel]\n",
    "\n",
    "def check_for_valid_game_board(game_board, player):\n",
    "    for kernel in detection_kernels:\n",
    "        if (convolve2d(game_board == player, kernel, mode=\"valid\") == 4).any():\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting lines\n",
      "Randomly selecting game boards\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting moves to game boards: 100%|█████████▉| 206060006/206062531 [15:49<00:00, 217485.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000000\n"
     ]
    }
   ],
   "source": [
    "print(\"Counting lines\")\n",
    "num_lines = sum(1 for _ in open(\"answers20.txt\"))\n",
    "available_game_boards = np.array([i for i in range(num_lines)])\n",
    "\n",
    "print(\"Randomly selecting game boards\")\n",
    "selected_game_boards = set(np.random.choice(available_game_boards, size=MAX_BOARDS, replace=False))\n",
    "del available_game_boards\n",
    "\n",
    "game_boards = np.zeros((MAX_BOARDS, BOARD_WIDTH, BOARD_HEIGHT), dtype=np.int8)\n",
    "game_results = np.zeros((MAX_BOARDS, BOARD_WIDTH), dtype=np.int8)\n",
    "with open(\"answers20.txt\", \"r\") as f:\n",
    "    curr_row = 0\n",
    "    board_index = 0\n",
    "\n",
    "    pbar = tqdm(total=num_lines, desc=\"Converting moves to game boards\")\n",
    "    for row in f:\n",
    "        if curr_row in selected_game_boards:\n",
    "            entries = row.split(\" \")\n",
    "\n",
    "            game_board = convert_moves_to_game_board(entries[0])\n",
    "\n",
    "            # if check_for_valid_game_board(game_board, 1) and check_for_valid_game_board(game_board, 2):\n",
    "            game_boards[board_index] = game_board\n",
    "\n",
    "            col_scores = get_col_scores(entries[1:])\n",
    "            max_value = np.max(col_scores)\n",
    "            game_results[board_index] = (col_scores == max_value)\n",
    "\n",
    "            board_index += 1\n",
    "\n",
    "        curr_row += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "print(len(game_boards))\n",
    "del selected_game_boards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 0 0 0]\n",
      "[0 0 0 1 0 0 0]\n",
      "[0 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(game_results[0])\n",
    "print(game_results[46456])\n",
    "print(game_results[2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Connect4Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, game_boards, game_results):\n",
    "        self.data = torch.from_numpy(game_boards)\n",
    "        self.targets = torch.from_numpy(game_results)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"num_epochs\": 30,\n",
    "    \"learning_rate\": 1e-8,\n",
    "    \"weight_decay\": 1e-2,\n",
    "    \"clip_quantile\": 0.75,\n",
    "    \"max_lr\": 1e-3,\n",
    "    \"batch_size\": 256,\n",
    "    \"test_prop\": 0.1,\n",
    "    \"val_prop\": 0.1,\n",
    "    \"device\": \"cuda:0\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from autoclip.torch import QuantileClip\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 32, kernel_size=5, padding=2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm2d(32),\n",
    "    torch.nn.Conv2d(32, 64, kernel_size=5, padding=2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm2d(64),\n",
    "    torch.nn.Conv2d(64, 128, kernel_size=5, padding=1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm2d(128),\n",
    "    torch.nn.Conv2d(128, 256, kernel_size=5, padding=1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm2d(256),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(256 * 3 * 2, 512),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.BatchNorm1d(512),\n",
    "    torch.nn.Dropout(0.2),\n",
    "    torch.nn.Linear(512, 128),    \n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.BatchNorm1d(128),\n",
    "    torch.nn.Dropout(0.2),\n",
    "    torch.nn.Linear(128, 7),\n",
    ").to(config[\"device\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Data Loaders\n",
    "num_training_examples = int(len(game_boards) * (1 - config[\"test_prop\"]))\n",
    "train_dataset = Connect4Dataset(game_boards[:num_training_examples], game_results[:num_training_examples])\n",
    "test_dataset = Connect4Dataset(game_boards[num_training_examples:], game_results[num_training_examples:])\n",
    "\n",
    "# Clear Memory\n",
    "del game_boards\n",
    "del game_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    num_workers=10,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    num_workers=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    ")\n",
    "optimizer = QuantileClip.as_optimizer(optimizer, config[\"clip_quantile\"])\n",
    "lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=config[\"max_lr\"],\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    epochs=config[\"num_epochs\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16352/3197656330.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor(loss_weights).to(config[\"device\"]))\n"
     ]
    }
   ],
   "source": [
    "from torch.cuda.amp import autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "positive_examples = torch.sum(train_dataset.targets)\n",
    "negative_examples = (len(train_dataset.targets)*BOARD_WIDTH) - positive_examples\n",
    "loss_weights =  negative_examples / positive_examples\n",
    "\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor(loss_weights).to(config[\"device\"]))\n",
    "scalar = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting moves to game boards: 100%|██████████| 206062531/206062531 [15:55<00:00, 215619.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 1/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 351563/351563 [1:13:20<00:00, 79.88it/s, loss=0.1956, accuracy=0.9383, f1=0.8816]\n",
      "Test: 100%|██████████| 39063/39063 [01:29<00:00, 436.15it/s, loss=0.1312, accuracy=0.9595, f1=0.9252]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 2/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 351563/351563 [1:15:03<00:00, 78.06it/s, loss=0.1388, accuracy=0.9570, f1=0.9158]\n",
      "Test: 100%|██████████| 39063/39063 [01:29<00:00, 435.09it/s, loss=0.1197, accuracy=0.9623, f1=0.9303]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 3/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 351563/351563 [1:14:43<00:00, 78.42it/s, loss=0.1310, accuracy=0.9596, f1=0.9207]\n",
      "Test: 100%|██████████| 39063/39063 [01:29<00:00, 437.15it/s, loss=0.1167, accuracy=0.9646, f1=0.9343]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 4/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 351563/351563 [1:14:52<00:00, 78.25it/s, loss=0.1282, accuracy=0.9606, f1=0.9225]\n",
      "Test: 100%|██████████| 39063/39063 [01:29<00:00, 434.20it/s, loss=0.1148, accuracy=0.9645, f1=0.9341]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 5/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 351563/351563 [1:15:50<00:00, 77.25it/s, loss=0.1276, accuracy=0.9609, f1=0.9230]\n",
      "Test: 100%|██████████| 39063/39063 [01:31<00:00, 425.03it/s, loss=0.1157, accuracy=0.9647, f1=0.9344]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 6/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 351563/351563 [1:17:34<00:00, 75.53it/s, loss=0.1275, accuracy=0.9609, f1=0.9231]\n",
      "Test: 100%|██████████| 39063/39063 [01:46<00:00, 368.23it/s, loss=0.1156, accuracy=0.9649, f1=0.9347]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 7/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 351563/351563 [1:19:53<00:00, 73.33it/s, loss=0.1274, accuracy=0.9609, f1=0.9231]  \n",
      "Test: 100%|██████████| 39063/39063 [01:49<00:00, 355.65it/s, loss=0.1152, accuracy=0.9645, f1=0.9341]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 8/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 351563/351563 [1:18:14<00:00, 74.89it/s, loss=0.1272, accuracy=0.9610, f1=0.9233] \n",
      "Test: 100%|██████████| 39063/39063 [01:43<00:00, 377.29it/s, loss=0.1141, accuracy=0.9628, f1=0.9315]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 9/30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 20096/351563 [02:58<48:59, 112.74it/s, loss=0.1266, accuracy=0.9611, f1=0.9235] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 26\u001b[0m\n\u001b[1;32m     22\u001b[0m     logits \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     23\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(logits, target)\n\u001b[0;32m---> 26\u001b[0m scalar\u001b[39m.\u001b[39;49mscale(loss)\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     27\u001b[0m scalar\u001b[39m.\u001b[39mstep(optimizer)\n\u001b[1;32m     28\u001b[0m scalar\u001b[39m.\u001b[39mupdate()\n",
      "File \u001b[0;32m~/miniconda3/envs/experiments/lib/python3.9/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/experiments/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Setup Training Loop\n",
    "pbar = tqdm(total=config[\"num_epochs\"], desc=\"Training\")\n",
    "device = config[\"device\"]\n",
    "bssf = None\n",
    "bssf_loss = torch.inf\n",
    "\n",
    "for epoch in range(config[\"num_epochs\"]):\n",
    "    print(f'--- Epoch {epoch+1}/{config[\"num_epochs\"]} ---')\n",
    "\n",
    "    # Train model\n",
    "    model.train()\n",
    "    training_losses = []\n",
    "    training_accuracies = []\n",
    "    training_confusion_matrix = np.zeros((2, 2), dtype=np.uint32)\n",
    "    p_bar = tqdm(train_loader, desc=\"Training\", position=0)\n",
    "    for data, target in p_bar:\n",
    "        data = data.to(device).float().unsqueeze(1)\n",
    "        target = target.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():\n",
    "            logits = model(data)\n",
    "            loss = loss_fn(logits, target)\n",
    "\n",
    "\n",
    "        scalar.scale(loss).backward()\n",
    "        scalar.step(optimizer)\n",
    "        scalar.update()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        training_losses.append(loss.item())\n",
    "\n",
    "\n",
    "        predictions = (logits > 0).detach().cpu().numpy()\n",
    "        detached_targets = target.detach().cpu().numpy()\n",
    "        is_correct = (predictions == detached_targets)\n",
    "\n",
    "        accuracy = np.mean(is_correct)\n",
    "        training_accuracies.append(accuracy)\n",
    "\n",
    "        # Calculate F1\n",
    "        training_confusion_matrix[0,0] += np.sum(np.logical_and(predictions == 0, detached_targets == 0))\n",
    "        training_confusion_matrix[0,1] += np.sum(np.logical_and(predictions == 0, detached_targets == 1))\n",
    "        training_confusion_matrix[1,0] += np.sum(np.logical_and(predictions == 1, detached_targets == 0))\n",
    "        training_confusion_matrix[1,1] += np.sum(np.logical_and(predictions == 1, detached_targets == 1))\n",
    "\n",
    "        f1 = (2*training_confusion_matrix[1,1] / (2*training_confusion_matrix[1,1] + training_confusion_matrix[0,1] + training_confusion_matrix[1,0]))\n",
    "\n",
    "\n",
    "        p_bar.set_postfix(\n",
    "            {\n",
    "                \"loss\": f\"{sum(training_losses)/len(training_losses):.4f}\",\n",
    "                \"accuracy\": f\"{sum(training_accuracies)/len(training_accuracies):.4f}\",\n",
    "                \"f1\": f\"{f1:.4f}\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_losses = []\n",
    "        test_accuracies = []\n",
    "        test_confusion_matrix = np.zeros((2, 2), dtype=np.uint32)\n",
    "        p_bar = tqdm(test_loader, desc=\"Test\", position=0)\n",
    "        for data, target in p_bar:\n",
    "            data = data.to(device).float().unsqueeze(1)\n",
    "            target = target.to(device).float()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with autocast():\n",
    "                logits = model(data)\n",
    "                loss = loss_fn(logits, target)\n",
    "\n",
    "            test_losses.append(loss.item())\n",
    "\n",
    "            # Calulate Accuracy and F1\n",
    "            predictions = (logits > 0).detach().cpu().numpy()\n",
    "            detached_targets = target.detach().cpu().numpy()\n",
    "            is_correct = (predictions == detached_targets)\n",
    "\n",
    "            accuracy = np.mean(is_correct)\n",
    "            test_accuracies.append(accuracy)\n",
    "\n",
    "            # Calculate F1\n",
    "            test_confusion_matrix[0,0] += np.sum(np.logical_and(predictions == 0, detached_targets == 0))\n",
    "            test_confusion_matrix[0,1] += np.sum(np.logical_and(predictions == 0, detached_targets == 1))\n",
    "            test_confusion_matrix[1,0] += np.sum(np.logical_and(predictions == 1, detached_targets == 0))\n",
    "            test_confusion_matrix[1,1] += np.sum(np.logical_and(predictions == 1, detached_targets == 1))\n",
    "\n",
    "            f1 = (2*test_confusion_matrix[1,1] / (2*test_confusion_matrix[1,1] + test_confusion_matrix[0,1] + test_confusion_matrix[1,0]))\n",
    "\n",
    "\n",
    "            p_bar.set_postfix(\n",
    "                {\n",
    "                    \"loss\": f\"{sum(test_losses)/len(test_losses):.4f}\",\n",
    "                    \"accuracy\": f\"{sum(test_accuracies)/len(test_accuracies):.4f}\",\n",
    "                    \"f1\": f\"{f1:.4f}\",\n",
    "                }\n",
    "            )\n",
    "\n",
    "        if sum(test_losses)/len(test_losses) < bssf_loss:\n",
    "            bssf_loss = sum(test_losses)/len(test_losses)\n",
    "            bssf = model\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test:   0%|          | 44/39063 [00:00<09:26, 68.91it/s, loss=0.1218, accuracy=0.9656, f1=0.9359] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test:   0%|          | 119/39063 [00:01<03:42, 174.97it/s, loss=0.1216, accuracy=0.9655, f1=0.9358]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test:   1%|          | 215/39063 [00:01<02:09, 300.21it/s, loss=0.1229, accuracy=0.9652, f1=0.9349]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test:   1%|          | 311/39063 [00:01<01:41, 380.92it/s, loss=0.1226, accuracy=0.9652, f1=0.9350]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test:   1%|          | 399/39063 [00:01<01:39, 387.14it/s, loss=0.1229, accuracy=0.9652, f1=0.9351]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test:   1%|▏         | 492/39063 [00:01<01:33, 412.83it/s, loss=0.1229, accuracy=0.9652, f1=0.9353]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test:   2%|▏         | 587/39063 [00:02<01:27, 441.59it/s, loss=0.1232, accuracy=0.9650, f1=0.9349]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test:   2%|▏         | 633/39063 [00:02<01:26, 446.61it/s, loss=0.1234, accuracy=0.9649, f1=0.9347]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n",
      "torch.Size([256, 1, 7, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test:   2%|▏         | 656/39063 [00:02<02:20, 273.05it/s, loss=0.1234, accuracy=0.9649, f1=0.9347]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m test_losses\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n\u001b[1;32m     19\u001b[0m \u001b[39m# Calulate Accuracy and F1\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m predictions \u001b[39m=\u001b[39m (logits \u001b[39m>\u001b[39;49m \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     21\u001b[0m detached_targets \u001b[39m=\u001b[39m target\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     22\u001b[0m is_correct \u001b[39m=\u001b[39m (predictions \u001b[39m==\u001b[39m detached_targets)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bssf.eval()\n",
    "with torch.no_grad():\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    test_confusion_matrix = np.zeros((2, 2), dtype=np.uint32)\n",
    "    p_bar = tqdm(test_loader, desc=\"Test\", position=0)\n",
    "    for data, target in p_bar:\n",
    "        data = data.to(device).float().unsqueeze(1)\n",
    "        print(data.shape)\n",
    "        target = target.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():\n",
    "            logits = bssf(data)\n",
    "            loss = loss_fn(logits, target)\n",
    "\n",
    "        test_losses.append(loss.item())\n",
    "\n",
    "        # Calulate Accuracy and F1\n",
    "        predictions = (logits > 0).detach().cpu().numpy()\n",
    "        detached_targets = target.detach().cpu().numpy()\n",
    "        is_correct = (predictions == detached_targets)\n",
    "\n",
    "        accuracy = np.mean(is_correct)\n",
    "        test_accuracies.append(accuracy)\n",
    "\n",
    "        # Calculate F1\n",
    "        test_confusion_matrix[0,0] += np.sum(np.logical_and(predictions == 0, detached_targets == 0))\n",
    "        test_confusion_matrix[0,1] += np.sum(np.logical_and(predictions == 0, detached_targets == 1))\n",
    "        test_confusion_matrix[1,0] += np.sum(np.logical_and(predictions == 1, detached_targets == 0))\n",
    "        test_confusion_matrix[1,1] += np.sum(np.logical_and(predictions == 1, detached_targets == 1))\n",
    "\n",
    "        f1 = (2*test_confusion_matrix[1,1] / (2*test_confusion_matrix[1,1] + test_confusion_matrix[0,1] + test_confusion_matrix[1,0]))\n",
    "\n",
    "\n",
    "        p_bar.set_postfix(\n",
    "            {\n",
    "                \"loss\": f\"{sum(test_losses)/len(test_losses):.4f}\",\n",
    "                \"accuracy\": f\"{sum(test_accuracies)/len(test_accuracies):.4f}\",\n",
    "                \"f1\": f\"{f1:.4f}\",\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "torch.save(bssf.state_dict(), f\"model_{now.minute}_{now.hour}_{now.day}_{now.month}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_name = f\"model_{now.minute}_{now.hour}_{now.day}_{now.month}.json\"\n",
    "with open(file_name, \"w\") as f:\n",
    "    metrics = {\"accuracy\": sum(test_accuracies)/len(test_accuracies), \"f1\": f1}\n",
    "    json.dump(metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# model.to(\"cpu\")\n",
    "# saved_model_dict = torch.load(\"model_1_0_2_12.pt\")\n",
    "# model.load_state_dict(saved_model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# game_board = np.zeros((BOARD_WIDTH, BOARD_HEIGHT))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0.]\n",
      " [1. 2. 0. 0. 0. 0.]\n",
      " [2. 1. 2. 2. 2. 1.]\n",
      " [2. 1. 2. 1. 1. 2.]\n",
      " [2. 2. 1. 2. 1. 1.]\n",
      " [1. 2. 2. 1. 1. 0.]\n",
      " [1. 2. 1. 2. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# game_board[6, 3] = 2\n",
    "# print(game_board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  3.8322,   8.6084, -17.3531,  -3.2702, -19.3175,   5.7995,  21.1401]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor(6)\n"
     ]
    }
   ],
   "source": [
    "# results = model(torch.tensor(game_board.reshape(1, 1, BOARD_WIDTH, BOARD_HEIGHT)).float())\n",
    "# print(results)\n",
    "# print(torch.argmax(results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('experiments')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c7ebe76d8d969ec5a1e9669fe2b882b7ab37dfff00812bf23b1b4f280354a721"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
